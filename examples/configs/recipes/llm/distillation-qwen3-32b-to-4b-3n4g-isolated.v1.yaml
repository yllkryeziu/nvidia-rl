defaults: ./distillation-qwen3-32b-to-4b-2n4g-fsdp2tp1-long.v1.yaml
distillation:
  resource_isolation:
    enabled: true
    teacher_resident_on_gpu: true
    roles:
      training:
        num_nodes: 1
        gpus_per_node: 4
      generation:
        num_nodes: 1
        gpus_per_node: 4
      teacher:
        num_nodes: 1
        gpus_per_node: 4
policy:
  max_total_sequence_length: 8192
  generation:
    vllm_cfg:
      max_model_len: 8192
teacher:
  model_name: /p/project1/envcomp/yll/.cache/huggingface/hub/models--Qwen--Qwen3-32B/snapshots/9216db5781bf21249d130ec9da846c4624c16137
  max_total_sequence_length: 8192
  dtensor_cfg:
    tensor_parallel_size: 4
    context_parallel_size: 1
checkpointing:
  checkpoint_dir: checkpoints/distillation-qwen3-32b-to-4b-3n4g-isolated
logger:
  log_dir: logs/distillation-qwen3-32b-to-4b-3n4g-isolated
  wandb:
    name: distillation-qwen3-32b-to-4b-3n4g-isolated
cluster:
  num_nodes: 3
  gpus_per_node: 4
